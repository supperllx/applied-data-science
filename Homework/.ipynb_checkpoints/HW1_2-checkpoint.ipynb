{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 \n",
    "In this proplem, you are requested to implement least square solution: $$\\min_x \\|Ax-y\\|^2,$$ where $\\textbf{A}$ is the input features while $y$ is the output. It is worth noticing that the first column of $\\textbf{A}$ is a vector with all elements to be $1$, that is: $A=[1,B]$. The solution of least square is given by: $(A^TA)^{-1}A^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_least_squares(B, y):\n",
    "    start_time = time.time()\n",
    "    B = np.asmatrix(B)\n",
    "    A = np.insert(B, 0, 1, axis=1)\n",
    "    y = np.asmatrix(y)\n",
    "    #beta = np.dot(np.linalg.inv(np.dot(A.T, A)),A.T)\n",
    "    beta = (((A.T * A).I) * A.T)*y\n",
    "    #beta = np.dot(beta, y)\n",
    "    #print(A.shape, y.shape)\n",
    "    end_time = time.time()\n",
    "    print(\"Time usage in Linear reg: \", end_time-start_time)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time usage in Linear reg:  0.0\n",
      "[[-0.1091319 ]\n",
      " [ 0.01136872]\n",
      " [ 0.1997561 ]\n",
      " [ 0.16809962]\n",
      " [ 0.1678848 ]\n",
      " [-0.05129102]\n",
      " [-0.08862598]\n",
      " [-0.09829118]\n",
      " [ 0.21266975]\n",
      " [-0.16107288]\n",
      " [-0.12474665]\n",
      " [-0.14819008]\n",
      " [ 0.02575863]\n",
      " [ 0.16413957]\n",
      " [ 0.24636913]\n",
      " [ 0.2017942 ]\n",
      " [ 0.02478866]\n",
      " [ 0.21840278]\n",
      " [-0.08530132]\n",
      " [ 0.09214667]\n",
      " [ 0.2409499 ]]\n"
     ]
    }
   ],
   "source": [
    "B=np.random.rand(100,20);\n",
    "y=np.random.rand(100,1);\n",
    "print(my_least_squares(B,y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 \n",
    "In this proplem, you are requested to implement least square solution by making use of gradient descent method: $$\\min_x \\|Ax-y\\|^2,$$ where $\\textbf{A}$ is the input features while $y$ is the output. What you should do is to first initialize (guess) $x_0$, then by making use of iterative updating: $x_{k+1}=x_{k}-\\lambda*\\Delta$, where $\\Delta$ is the gradient of the objective function with respective to $x_k$. $\\lambda$ is the so-called learning rate and should be set to be small to avoid gradient explosion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gradient_descent(B, y):\n",
    "    start_time = time.time()\n",
    "    B = np.asmatrix(B)\n",
    "    A = np.insert(B, 0, 1, axis=1)\n",
    "    beta_size = A.shape[1]\n",
    "    y = np.asmatrix(y)\n",
    "    \n",
    "    beta = np.asmatrix(np.random.rand(beta_size, 1))\n",
    "    #print(beta)\n",
    "    alpha = 0.0001\n",
    "    K = 100000\n",
    "    for i in range(K):\n",
    "        beta = beta - alpha*((A.T * A)*beta - A.T*y)\n",
    "    end_time = time.time()\n",
    "    print(\"time usage in Gradient descent: \", end_time-start_time)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time usage in Gradient descent:  16.808428525924683\n",
      "[[ 8.86382973e-01]\n",
      " [-1.10353464e-01]\n",
      " [ 5.95933963e-03]\n",
      " [ 3.78096927e-02]\n",
      " [-2.37268891e-02]\n",
      " [-5.86139910e-02]\n",
      " [ 2.50783245e-02]\n",
      " [-5.93725851e-02]\n",
      " [ 5.89402209e-02]\n",
      " [ 4.54472303e-03]\n",
      " [ 1.19269428e-02]\n",
      " [-4.31011678e-02]\n",
      " [-8.48219567e-02]\n",
      " [-1.07239782e-02]\n",
      " [-3.21051817e-02]\n",
      " [-4.58087564e-04]\n",
      " [ 2.16578937e-02]\n",
      " [-4.74143090e-02]\n",
      " [-9.31261370e-03]\n",
      " [ 6.15363258e-02]\n",
      " [-3.99540328e-03]\n",
      " [-1.26640782e-01]\n",
      " [-8.11771546e-02]\n",
      " [-5.70429462e-03]\n",
      " [ 3.10785410e-02]\n",
      " [ 7.62435900e-02]\n",
      " [-8.13447509e-02]\n",
      " [-4.38424976e-03]\n",
      " [ 8.50026066e-02]\n",
      " [-1.30773021e-02]\n",
      " [-2.36196937e-03]\n",
      " [ 1.25914801e-01]\n",
      " [ 1.18973286e-01]\n",
      " [-1.13130121e-01]\n",
      " [-5.44948767e-02]\n",
      " [ 1.45776435e-02]\n",
      " [-1.46648388e-01]\n",
      " [ 1.18341783e-02]\n",
      " [-1.49971877e-02]\n",
      " [-4.23946186e-02]\n",
      " [ 1.09538274e-02]\n",
      " [ 1.37500316e-02]\n",
      " [ 1.72211589e-02]\n",
      " [ 4.03785301e-02]\n",
      " [ 7.79935573e-04]\n",
      " [ 9.85416771e-02]\n",
      " [ 5.25250684e-03]\n",
      " [-3.35968850e-02]\n",
      " [ 9.69139048e-02]\n",
      " [-3.33984130e-02]\n",
      " [ 3.04999595e-02]\n",
      " [ 9.93292000e-03]\n",
      " [ 3.64018331e-02]\n",
      " [ 1.32197665e-03]\n",
      " [-3.53168438e-02]\n",
      " [-1.43651125e-02]\n",
      " [-6.10775028e-02]\n",
      " [-4.97426385e-02]\n",
      " [ 6.92066306e-02]\n",
      " [-3.96994548e-02]\n",
      " [-8.21608091e-02]\n",
      " [-5.88764848e-02]\n",
      " [-3.45014845e-02]\n",
      " [-4.06607767e-03]\n",
      " [-1.98954920e-02]\n",
      " [-2.40674618e-02]\n",
      " [ 3.61749064e-02]\n",
      " [-1.26401831e-02]\n",
      " [-4.56278397e-02]\n",
      " [-1.90917908e-02]\n",
      " [ 5.78080591e-03]\n",
      " [-4.82186708e-02]\n",
      " [-5.51538299e-05]\n",
      " [ 9.31286336e-02]\n",
      " [-3.39584676e-02]\n",
      " [ 4.48802590e-02]\n",
      " [ 6.05249601e-02]\n",
      " [ 1.07977115e-01]\n",
      " [-1.70857810e-02]\n",
      " [ 2.42372775e-02]\n",
      " [-5.04871684e-02]\n",
      " [-1.28058748e-01]\n",
      " [ 3.89440634e-02]\n",
      " [-4.94445144e-02]\n",
      " [ 2.96735038e-02]\n",
      " [-6.57985855e-02]\n",
      " [ 6.67962254e-04]\n",
      " [-1.25757677e-01]\n",
      " [-2.28683252e-02]\n",
      " [ 4.22296408e-02]\n",
      " [-2.50323032e-02]\n",
      " [-1.14606609e-02]\n",
      " [ 4.21984493e-02]\n",
      " [-4.53167364e-03]\n",
      " [-4.90696251e-02]\n",
      " [ 3.30777522e-02]\n",
      " [ 4.29514385e-02]\n",
      " [ 6.34852898e-02]\n",
      " [-1.02760111e-02]\n",
      " [-1.14544152e-01]\n",
      " [-4.72384835e-02]]\n"
     ]
    }
   ],
   "source": [
    "B=np.random.rand(400,100);\n",
    "y=np.random.rand(400,1);\n",
    "print(my_gradient_descent(B,y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time usage in Gradient descent:  2.6267669200897217\n",
      "[[0.00342456]\n",
      " [1.99883523]]\n"
     ]
    }
   ],
   "source": [
    "a =np.matrix([[1],[2],[3],[4]])\n",
    "y=np.matrix([2,4,6,8]).T\n",
    "\n",
    "res = my_gradient_descent(a,y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
